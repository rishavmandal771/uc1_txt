{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7b2da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m opt\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_transformers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import strftime, localtime\n",
    "from collections import Counter\n",
    "from config import opt\n",
    "from pytorch_transformers import BertTokenizer\n",
    "import random\n",
    "import models\n",
    "from utils import get_dataloader\n",
    "from seqeval.metrics import f1_score, accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import numpy as np \n",
    "import torch \n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef858fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369b5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    torch.cuda.empty_cache()\n",
    "    log_file = '{}-{}.log'.format(opt.model, strftime(\"%y%m%d-%H%M\", localtime()))\n",
    "    logger.addHandler(logging.FileHandler(log_file))\n",
    "\n",
    "    att_list = [\"brand\"]\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(opt.pretrained_bert_name)\n",
    "    tags2id = {'':0,'B':1,'I':2,'O':3}\n",
    "    id2tags = {v:k for k,v in tags2id.items()}\n",
    "\n",
    "    opt._parse(kwargs)\n",
    "\n",
    "    if opt.seed is not None:\n",
    "        random.seed(opt.seed)\n",
    "        np.random.seed(opt.seed)\n",
    "        torch.manual_seed(opt.seed)\n",
    "        torch.cuda.manual_seed(opt.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "   \n",
    "    # step1: configure model\n",
    "    model = getattr(models, opt.model)(opt)\n",
    "    if opt.load_model_path:\n",
    "        the_model = torch.load(PATH)\n",
    "    model.to(opt.device)\n",
    "\n",
    "    # step2: data\n",
    "    train_dataloader,valid_dataloader,test_dataloader = get_dataloader(opt)\n",
    "    \n",
    "    # step3: criterion and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    lr = opt.lr\n",
    "    optimizer = model.get_optimizer(lr, opt.weight_decay)\n",
    "    \n",
    "\n",
    "    # step4 train\n",
    "    for epoch in range(opt.max_epoch):\n",
    "        model.train()\n",
    "        for ii,batch in tqdm(enumerate(train_dataloader)):\n",
    "            \n",
    "            # train model\n",
    "            optimizer.zero_grad()\n",
    "            x = batch['x'].to(opt.device)\n",
    "            y = batch['y'].to(opt.device)\n",
    "            att = batch['att'].to(opt.device)\n",
    "            inputs = [x, att, y]\n",
    "            loss = model.log_likelihood(inputs)\n",
    "            loss.backward()\n",
    "            #CRF\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=3)\n",
    "            optimizer.step()\n",
    "            if ii % opt.print_freq == 0:\n",
    "                print('epoch:%04d,------------loss:%f'%(epoch,loss.item()))\n",
    "\n",
    "    torch.save(model.state_dict(), f'data/finetuned_BERT_epoch_model.pth')\n",
    "    preds, labels = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(valid_dataloader):\n",
    "\n",
    "            x = batch['x'].to(opt.device)\n",
    "            y = batch['y'].to(opt.device)\n",
    "            att = batch['att'].to(opt.device)\n",
    "            inputs = [x, att, y]\n",
    "            predict = model(inputs)\n",
    "            \n",
    "            predict_list = predict.tolist()[0] \n",
    "\n",
    "            # 统计非0的，也就是真实标签的长度\n",
    "            leng = []\n",
    "            for i in y.cpu():\n",
    "                # Check the device of the tensor\n",
    "                tmp = []\n",
    "                for j in i:\n",
    "                    if j.item()>0:\n",
    "                        tmp.append(j.item())\n",
    "                leng.append(tmp)\n",
    "\n",
    "\n",
    "            for index, i in enumerate(predict_list):\n",
    "                preds.append([id2tags[k] if k>0 else id2tags[3] for k in i[:len(leng[index])]])\n",
    "                # preds += i[:len(leng[index])]\n",
    "\n",
    "            for index, i in enumerate(y.tolist()):\n",
    "                labels.append([id2tags[k] if k>0 else id2tags[3] for k in i[:len(leng[index])]])\n",
    "                #labels += i[:len(leng[index])]\n",
    "        #precision = precision_score(labels, preds, average='macro')\n",
    "        #recall = recall_score(labels, preds, average='macro')\n",
    "        #f1 = f1_score(labels, preds, average='macro')\n",
    "        report = classification_report(labels, preds)\n",
    "        print(report)\n",
    "        logger.info(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214c60d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\madri\\.cache\\torch\\pytorch_transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\madri\\.cache\\torch\\pytorch_transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\madri\\.cache\\torch\\pytorch_transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "train len: (17410, 40)\n",
      "test len: (774, 40)\n",
      "valid len (1161, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\madri\\Documents\\Safira.ai\\Use Case 1\\OpenTag_2019\\models\\OpenTag_2019.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(context != 0, dtype=torch.uint8)\n",
      "C:\\Users\\madri\\Documents\\Safira.ai\\Use Case 1\\OpenTag_2019\\models\\new_crf.py:240: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorCompare.cpp:493.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "1it [00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0000,------------loss:51.560589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:18,  1.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii,batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataloader)):\n\u001b[0;32m     41\u001b[0m     \n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(opt\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     46\u001b[0m     att \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(opt\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7ac1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step5: evaluation on test data\n",
    "model = getattr(models, opt.model)(opt)\n",
    "\n",
    "model.load_state_dict(torch.load(f'data/finetuned_BERT_epoch_model.pth'))\n",
    "model.to(opt.device)\n",
    "\n",
    "# step2: data\n",
    "train_dataloader,valid_dataloader,test_dataloader = get_dataloader(opt)\n",
    "tokenizer = BertTokenizer.from_pretrained(opt.pretrained_bert_name)\n",
    "\n",
    "preds, labels = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for index, batch in enumerate(test_dataloader):\n",
    "            x = batch['x'].to(opt.device)\n",
    "            y = batch['y'].to(opt.device)\n",
    "            att = batch['att'].to(opt.device)\n",
    "            \n",
    "            inputs = [x, att]\n",
    "            predict = model(inputs)\n",
    "            \n",
    "            print(inputs)\n",
    "            \n",
    "\n",
    "            \n",
    "            predict_list = predict.tolist()[0] \n",
    "\n",
    "            \n",
    "            \n",
    "            for i in range(len(batch)):\n",
    "                start_p, end_p, start_y, end_y = 0,0,0,0\n",
    "                for index,value in enumerate(predict_list[i]):\n",
    "                    if value == 1:\n",
    "                        start_p = index\n",
    "                        j = index\n",
    "                        while(predict_list[i][j]!=3):\n",
    "                            j = j + 1\n",
    "                            end_p = j\n",
    "\n",
    "                for index,value in enumerate(y[i]):\n",
    "                    if value == 1:\n",
    "                        start_y = index\n",
    "                        j = index\n",
    "                        while(y[i][j]!=3):\n",
    "                            j = j + 1\n",
    "                            end_y = j\n",
    "                \n",
    "                print(start_p)\n",
    "                preds = (x[i][start_p : end_p])\n",
    "                words_p = tokenizer.convert_ids_to_tokens([i.item() for i in preds.cpu() if i.item()>0])\n",
    "                labels = (x[i][start_y : end_y])\n",
    "                words_l = tokenizer.convert_ids_to_tokens([i.item() for i in labels.cpu() if i.item()>0])\n",
    "            \n",
    "                words = tokenizer.convert_ids_to_tokens([i.item() for i in x[i].cpu() if i.item()>0])\n",
    "                print('\\nTitle: ',' '.join(words))\n",
    "                print('\\nAttribute: ',tokenizer.convert_ids_to_tokens([i.item() for i in att[i].cpu() if i.item()>0]))\n",
    "                print('\\nPred label: ',' '.join(words_p), ' ')\n",
    "                print('\\nActual label: ', ' '.join(words_l))\n",
    "    \n",
    "\n",
    "            \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ef5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from os import path\n",
    "\n",
    "filename = 'sam.json'\n",
    "\n",
    "json_data = []\n",
    "\n",
    "    \n",
    "\n",
    "# Read JSON file\n",
    "with open(filename) as fp:\n",
    "  json_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e7970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = json_data[\"input_data\"][\"title\"]\n",
    "att = json_data[\"input_data\"][\"attributes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8f2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\madri\\.cache\\torch\\pytorch_transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def is_english_char(cp):\n",
    "    \"\"\"Checks whether CP is the codepoint of an English character.\"\"\"\n",
    "    if (\n",
    "        (cp >= 0x0041 and cp <= 0x005A)\n",
    "        or (cp >= 0x0061 and cp <= 0x007A)  # uppercase A-Z\n",
    "        or (cp >= 0x00C0 and cp <= 0x00FF)  # lowercase a-z\n",
    "        or (cp >= 0x0100 and cp <= 0x017F)  # Latin-1 Supplement\n",
    "        or (cp >= 0x0180 and cp <= 0x024F)  # Latin Extended-A\n",
    "        or (cp >= 0x1E00 and cp <= 0x1EFF)  # Latin Extended-B\n",
    "        or (cp >= 0x2C60 and cp <= 0x2C7F)  # Latin Extended Additional\n",
    "        or (cp >= 0xA720 and cp <= 0xA7FF)  # Latin Extended-C\n",
    "        or (cp >= 0xAB30 and cp <= 0xAB6F)  # Latin Extended-D\n",
    "        or (cp >= 0xFB00 and cp <= 0xFB06)  # Latin Extended-E\n",
    "    ):  # Alphabetic Presentation Forms\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "max_len = 40\n",
    "\n",
    "def X_padding(ids):\n",
    "    if len(ids) >= max_len:\n",
    "        return ids[:max_len]\n",
    "    ids.extend([0] * (max_len - len(ids)))\n",
    "    return ids\n",
    "\n",
    "tag_max_len = 6\n",
    "\n",
    "def tag_padding(ids):\n",
    "    if len(ids) >= tag_max_len:\n",
    "        return ids[:tag_max_len]\n",
    "    ids.extend([0] * (tag_max_len - len(ids)))\n",
    "    return ids\n",
    "\n",
    "def nobert4token(tokenizer, title, attribute):\n",
    "    def get_char(sent):\n",
    "        tmp = []\n",
    "        s = \"\"\n",
    "        for char in sent.strip():\n",
    "            if char.strip():\n",
    "                cp = ord(char)\n",
    "                if is_english_char(cp):\n",
    "                    if s:\n",
    "                        tmp.append(s)\n",
    "                    tmp.append(char)\n",
    "                    s = \"\"\n",
    "                else:\n",
    "                    s += char\n",
    "            elif s:\n",
    "                tmp.append(s)\n",
    "                s = \"\"\n",
    "        if s:\n",
    "            tmp.append(s)\n",
    "        return tmp\n",
    "\n",
    "    title_list = get_char(title)\n",
    "    attribute_list = get_char(attribute)\n",
    "\n",
    "    title_list = tokenizer.convert_tokens_to_ids(title_list)\n",
    "    attribute_list = tokenizer.convert_tokens_to_ids(attribute_list)\n",
    "\n",
    "\n",
    "    return title_list, attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12851219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madri\\Documents\\Safira.ai\\Use Case 1\\OpenTag_2019\\models\\new_crf.py:304: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorCompare.cpp:493.)\n",
      "  score = torch.where(mask[i].unsqueeze(-1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "for i in range(len(title)):\n",
    "\n",
    "    my_dict = {}\n",
    "    for j in range(len(att)):\n",
    "        \n",
    "        attr = att[i][j]\n",
    "\n",
    "        t, a = nobert4token(tokenizer, title[i], attr)\n",
    "\n",
    "        x = X_padding(t)\n",
    "        y = tag_padding(a)\n",
    "\n",
    "        tensor_a = torch.tensor(y, dtype=torch.int32)\n",
    "        tensor_a = torch.unsqueeze(tensor_a, dim=0).to('cuda')\n",
    "\n",
    "        tensor_t = torch.tensor(x, dtype=torch.int32)\n",
    "        tensor_t = torch.unsqueeze(tensor_t, dim=0).to('cuda')\n",
    "\n",
    "        output = model([tensor_t, tensor_a])\n",
    "\n",
    "        predict_list = output.tolist()[0]\n",
    "\n",
    "        for k in range(len(predict_list)):\n",
    "            start_p, end_p = 0, 0\n",
    "            for index, value in enumerate(predict_list[k]):\n",
    "                if value == 1:\n",
    "                    start_p = index\n",
    "                    ind = index\n",
    "                    while predict_list[k][ind] != 3:\n",
    "                        ind = ind + 1\n",
    "                        end_p = ind\n",
    "            preds = tensor_t[k][start_p:end_p]\n",
    "            words_p = tokenizer.convert_ids_to_tokens(\n",
    "                [k.item() for k in preds.cpu() if k.item() > 0])\n",
    "        \n",
    "        my_dict[attr] = \" \".join(words_p)\n",
    "        \n",
    "        str =  \" \".join(words_p)\n",
    "        print(type(str))\n",
    "\n",
    "    result[title[i]] = my_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50697b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Lee posh Lactic Acid 60% Anti ageing Pigmentation Removing Glow Peel ': {'brand': '[UNK]',\n",
       "  'hello': '[UNK]'},\n",
       " ' Generic Anti Snoring Snore Stopper Sleep Apnea Solution Lips Plasters Soft Space Cotton ': {'brand': '[UNK]',\n",
       "  'hello': '[UNK]'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44272177",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_input = tensor_t.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22801df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model([title_input,tensor_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e796660",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model([title_input,tensor_a.to('cuda')])\n",
    "\n",
    "predict_list = output.tolist()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef6daf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca38257",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = [\"brand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e509686",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\madri\\.cache\\torch\\pytorch_transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\madri\\.cache\\torch\\pytorch_transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenTag2019(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (word_embeds): Embedding(30000, 768)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (squeeze_embedding): SqueezeEmbedding()\n",
       "  (lstm): LSTM(768, 512, batch_first=True, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=2048, out_features=4, bias=True)\n",
       "  (crf): CRF(num_tags=4)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = getattr(models, opt.model)(opt)\n",
    "model.load_state_dict(torch.load(f'data/finetuned_BERT_epoch_model.pth'))\n",
    "model.to(opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predict_list)):\n",
    "                start_p, end_p= 0,0\n",
    "                for index,value in enumerate(predict_list[i]):\n",
    "                    if value == 1:\n",
    "                        start_p = index\n",
    "                        j = index\n",
    "                        while(predict_list[i][j]!=3):\n",
    "                            j = j + 1\n",
    "                            end_p = j\n",
    "                print(start_p)\n",
    "                preds = (title_input.to('cuda')[i][start_p : end_p])\n",
    "                print(preds)\n",
    "                words_p = tokenizer.convert_ids_to_tokens([i.item() for i in preds.cpu() if i.item()>0])\n",
    "                print(words_p)\n",
    "            \n",
    "\n",
    "                print('\\nTitle: ',title)\n",
    "                print('\\nAttribute: ',att[i])\n",
    "                print('\\nPred label: ',' '.join(words_p), ' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65393c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe96ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsna",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
